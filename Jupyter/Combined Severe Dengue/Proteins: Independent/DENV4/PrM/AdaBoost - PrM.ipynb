{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the protein data\n",
    "k2 = []\n",
    "k2d = []\n",
    "\n",
    "f = open(\"../../../../../../Data/Proteins/DENV4/PrM/DENV4_Premembrane.txt\", \"r\")\n",
    "for x in f:\n",
    "    if \"DSS\" in x:\n",
    "        k2d.append(1)\n",
    "    elif \"DHF\" in x:\n",
    "        k2d.append(1)\n",
    "    elif x[0] == \">\":\n",
    "        k2d.append(0)\n",
    "    else:\n",
    "        x = x.replace(\"\\n\", \"\")\n",
    "        k2.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the array into DataFrame\n",
    "k2 = pd.DataFrame(k2)\n",
    "\n",
    "# Attaching the \"Disease\" label column to the input\n",
    "k2[\"Disease\"] = k2d\n",
    "\n",
    "# Renaming the columns\n",
    "k2 = k2.rename(index=str, columns={0: \"Sequence\", \"Disease\": \"Disease\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined shape of the given data is: (50, 2)\n",
      "The length of the combined data is: 50\n",
      "Does the combined data have any null value? -> False\n",
      "                                             Sequence  Disease\n",
      "41  FHLSTRDGEPLMIVAKHERGRPLLFKTTEGINKCTLIAMDLGEMCE...        0\n",
      "6   FHLSTRDGEPLMIVAKHERGRPLLFKTTEGINKCTLIAMDLGEMCE...        0\n",
      "0   FHLSTRDGEPLMIVAKHERGRPLLFKTTEGINKCTLIAMDLGEMCE...        0\n",
      "24  FHLSTRDGEPLMIVAKHERGRPLLFKTTEGINKCTLIAMDLGEMCE...        0\n",
      "1   FHLSTRDGEPLMIVAKHERGRPLLFKTTEGINKCTLIAMDLGEMCE...        0\n"
     ]
    }
   ],
   "source": [
    "print(\"The combined shape of the given data is:\", str(k2.shape))\n",
    "print(\"The length of the combined data is:\", str(len(k2.index)))\n",
    "print(\"Does the combined data have any null value? ->\", k2.isnull().values.any())\n",
    "\n",
    "k2 = k2.dropna(how = 'any', axis = 0) \n",
    "\n",
    "# Shuffling the data and then taking a peek\n",
    "k2 = k2.sample(frac = 1)\n",
    "print(k2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\n",
    "def getKmers(sequence, size = 6):\n",
    "    return [sequence[x:x + size].lower() for x in range(len(sequence) - size + 1)]\n",
    "\n",
    "k2['words'] = k2.apply(lambda x: getKmers(x['Sequence']), axis = 1)\n",
    "k2 = k2.drop('Sequence', axis=1)\n",
    "\n",
    "k2_texts = list(k2['words'])\n",
    "for item in range(len(k2_texts)):\n",
    "    k2_texts[item] = ' '.join(k2_texts[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of y is: (50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9c0efd0630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating y and printing the shape of it\n",
    "y = k2.iloc[:, 0].values\n",
    "print(\"The shape of y is:\", y.shape)\n",
    "\n",
    "# Checking the balance of the disease severity\n",
    "k2[\"Disease\"].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x matrix is: (50, 239)\n"
     ]
    }
   ],
   "source": [
    "# Creating the Bag of Words model using CountVectorizer()\n",
    "# This is equivalent to k-mer counting\n",
    "# The n-gram size of 4 was previously determined by testing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(4,4))\n",
    "x = cv.fit_transform(k2_texts)\n",
    "\n",
    "# Print the shape of x\n",
    "print(\"The shape of x matrix is:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is: (40, 239)\n",
      "The shape of y_train is: (40,)\n",
      "The shape of x_test is: (10, 239)\n",
      "The shape of y_test is: (10,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the human dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# Printing the shapes of the train and test matrices\n",
    "print(\"The shape of x_train is:\", X_train.shape)\n",
    "print(\"The shape of y_train is:\", y_train.shape)\n",
    "print(\"The shape of x_test is:\", X_test.shape)\n",
    "print(\"The shape of y_test is:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "Predicted  0\n",
      "Actual      \n",
      "0          8\n",
      "1          2\n",
      "\n",
      "accuracy = 0.8 \n",
      "precision = 0.64 \n",
      "recall = 0.8 \n",
      "f1 = 0.7111111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "print(\"Confusion matrix\")\n",
    "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n",
    "\n",
    "def get_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "print(\"\\naccuracy = {} \\nprecision = {} \\nrecall = {} \\nf1 = {}\".format(accuracy, precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
